{"cells":[{"cell_type":"markdown","source":["# Model Experimentation"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7c2edc36-8cc7-4d64-8083-c8be0544c3b7","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Notebook Setup"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2e7e856d-4344-4996-ac25-4088b6fc8ec7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%pip install timezonefinder\n%pip install tzfpy"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"f641d51a-88a4-46ab-bb0c-5686243a68b0","inputWidgets":{},"title":"Install Modules"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Python interpreter will be restarted.\nRequirement already satisfied: timezonefinder in /local_disk0/.ephemeral_nfs/envs/pythonEnv-41591ab9-acab-4c88-97cc-85f48267dc28/lib/python3.9/site-packages (6.1.8)\nRequirement already satisfied: h3<4,>=3.7.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-41591ab9-acab-4c88-97cc-85f48267dc28/lib/python3.9/site-packages (from timezonefinder) (3.7.6)\nRequirement already satisfied: cffi<2,>=1.15.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-41591ab9-acab-4c88-97cc-85f48267dc28/lib/python3.9/site-packages (from timezonefinder) (1.15.1)\nRequirement already satisfied: setuptools>=65.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-41591ab9-acab-4c88-97cc-85f48267dc28/lib/python3.9/site-packages (from timezonefinder) (65.6.3)\nRequirement already satisfied: numpy<2,>=1.18 in /databricks/python3/lib/python3.9/site-packages (from timezonefinder) (1.20.3)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.9/site-packages (from cffi<2,>=1.15.1->timezonefinder) (2.20)\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nRequirement already satisfied: tzfpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-41591ab9-acab-4c88-97cc-85f48267dc28/lib/python3.9/site-packages (0.11.2)\nPython interpreter will be restarted.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Python interpreter will be restarted.\nRequirement already satisfied: timezonefinder in /local_disk0/.ephemeral_nfs/envs/pythonEnv-41591ab9-acab-4c88-97cc-85f48267dc28/lib/python3.9/site-packages (6.1.8)\nRequirement already satisfied: h3<4,>=3.7.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-41591ab9-acab-4c88-97cc-85f48267dc28/lib/python3.9/site-packages (from timezonefinder) (3.7.6)\nRequirement already satisfied: cffi<2,>=1.15.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-41591ab9-acab-4c88-97cc-85f48267dc28/lib/python3.9/site-packages (from timezonefinder) (1.15.1)\nRequirement already satisfied: setuptools>=65.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-41591ab9-acab-4c88-97cc-85f48267dc28/lib/python3.9/site-packages (from timezonefinder) (65.6.3)\nRequirement already satisfied: numpy<2,>=1.18 in /databricks/python3/lib/python3.9/site-packages (from timezonefinder) (1.20.3)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.9/site-packages (from cffi<2,>=1.15.1->timezonefinder) (2.20)\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nRequirement already satisfied: tzfpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-41591ab9-acab-4c88-97cc-85f48267dc28/lib/python3.9/site-packages (0.11.2)\nPython interpreter will be restarted.\n"]}}],"execution_count":0},{"cell_type":"code","source":["# General \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport sys\nfrom statistics import mean\nimport itertools\nimport mlflow.spark\n\n# PySpark \nfrom pyspark.sql.functions import col,isnan,when,count\nfrom pyspark.sql.functions import regexp_replace\n\n# SQL Functions\nfrom pyspark.sql import functions as f\nfrom pyspark.sql.functions import monotonically_increasing_id, to_timestamp, to_utc_timestamp, to_date\nfrom pyspark.sql.functions import isnan, when, count, col, isnull, percent_rank, first, dense_rank\nfrom pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, NullType, ShortType, DateType, BooleanType, BinaryType, FloatType, DecimalType\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.window import Window\nfrom pyspark.streaming import StreamingContext\nfrom pyspark.sql import Row\nfrom functools import reduce\nfrom pyspark.sql.functions import rand,col,when,concat,substring,lit,udf,lower,sum as ps_sum,count as ps_count,row_number\nfrom pyspark.sql.window import *\nfrom pyspark.sql import DataFrame\nfrom pyspark.ml.stat import Correlation\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.linalg import DenseMatrix, Vectors\nfrom pyspark.sql.functions import row_number\n\n# ML\nfrom pyspark.ml.stat import Correlation\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, MultilayerPerceptronClassifier\nfrom pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, RandomForestRegressor, GBTRegressor#, MultilayerPerceptronRegressor\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler, OneHotEncoder\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator#, MulticlassRegressionEvaluator\n\n# Misc \nfrom pandas.tseries.holiday import USFederalHolidayCalendar as calendar\nfrom timezonefinder import TimezoneFinder\nfrom tzfpy import get_tz"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"86437001-ff1b-4d65-a465-d8f67a4b7beb","inputWidgets":{},"title":"Import Modules"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":{"text/plain":"","application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"},"removedWidgets":[],"addedWidgets":{},"metadata":{"kernelSessionId":"2ba884f0-a594cddbdd44c5ae1aa8a793"},"type":"mimeBundle","arguments":{}}},"output_type":"display_data","data":{"text/plain":"","application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"}}],"execution_count":0},{"cell_type":"code","source":["# Display and define where mids-w261 is located\ndata_BASE_DIR = \"dbfs:/mnt/mids-w261/\"\n# display(dbutils.fs.ls(f\"{data_BASE_DIR}\"))\n\n# Inspect the Mount's Final Project folder \ndata_BASE_DIR = \"dbfs:/mnt/mids-w261/datasets_final_project_2022/\"\n# display(dbutils.fs.ls(f\"{data_BASE_DIR}\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"8ea5cf50-f7c0-415d-9894-734ac509088c","inputWidgets":{},"title":"Locate Data"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["blob_container = \"housestark\" # The name of your container created in https://portal.azure.com\nstorage_account = \"neilp\" # The name of your Storage account created in https://portal.azure.com\nsecret_scope = \"w261_s1g4\" # The name of the scope created in your local computer using the Databricks CLI\nsecret_key = \"w261_s1g4_key\" # The name of the secret key created in your local computer using the Databricks CLI \nblob_url = f\"wasbs://{blob_container}@{storage_account}.blob.core.windows.net\"\nmount_path = \"/mnt/mids-w261\""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"bd7ce097-a7ef-4750-80fa-9c54dc6a568a","inputWidgets":{},"title":"Blob info"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark.conf.set(\n  f\"fs.azure.sas.{blob_container}.{storage_account}.blob.core.windows.net\",\n  dbutils.secrets.get(scope = secret_scope, key = secret_key)\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"18f526af-51c0-4652-96a3-ab8912d99f7a","inputWidgets":{},"title":"Blob info (II)"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# df = spark.read.parquet(f\"{blob_url}/df_main_3m\")\ndf_full = spark.read.parquet(f\"{blob_url}/df_main_fullClean\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"9cc8a760-8146-448e-b20e-d0824cd52813","inputWidgets":{},"title":"Read In Key Files"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Helper Functions"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4bfb461d-5613-40e4-b909-067046f52a8f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def preModeling_dataEdit(df):\n  '''\n  Input: df that has already gone through the final join, cleaning, and feature engineering\n  Output: df that includes null imputing and # and % of flights (by tail number) that were delayed and cancelled in the past 90 days --> these depend on window functions, as such they need to be done right after the data is split for modelling and not during feature engineering phase\n  '''\n  \n  ### FINAL CLEANING \n  # Remove rows with null scheduled_departure_UTC because these are rows without a proper timezone (timezonefinder could not find)\n  df = df.na.drop(subset=[\"scheduled_departure_UTC\"])\n  dropCols = ['TAXI_IN', 'TAXI_OUT']\n  df = df.drop(*dropCols) \n\n  \n  ### FINAL FEATURE ADDITIONS\n  ## GET NUMBER & PERCENTAGE OF TIMES A PLANE (BY TAIL NUMBER) HAS BEEN DELAYED OR CANCELLED IN THE PAST 3 MONTHS (2 COLUMNS)\n  # Make window function\n  df = df.withColumn('roundedMonth', f.date_trunc('month', df.scheduled_departure_UTC))\n  window_3m = Window().partitionBy('TAIL_NUM').orderBy(f.col('roundedMonth').cast('long')).rangeBetween(-(86400), 0) # changed to 1 day instead of 3 months \n\n  # Add in Columns\n  # Number of flights delayed/cancelled\n  df = df.withColumn('no_delays_last1d', when(df.TAIL_NUM.isNotNull(), f.sum('dep_delay_15').over(window_3m)).otherwise(-1)) \\\n         .withColumn('no_cancellation_last1d', when(df.TAIL_NUM.isNotNull(), f.sum('CANCELLED').over(window_3m)).otherwise(-1)) \n  # Percentage of flights delayed/cancelled\n  df = df.withColumn('count_flights_last1d', when(df.TAIL_NUM.isNotNull(), f.count('TAIL_NUM').over(window_3m)).otherwise(-1)) \n  df = df.withColumn('perc_delays_last1d', when(df.count_flights_last1d != -1, (df.no_delays_last1d/ df.count_flights_last1d)).otherwise(-1.0)) \\\n         .withColumn('perc_cancellation_last1d', when(df.count_flights_last1d != -1, (df.no_cancellation_last1d/ df.count_flights_last1d)).otherwise(-1.0))     \n  \n  ### HANDLING NULLS\n  ## Imputing Hourly Weather Data to the best of our ability (up to 3 hours back)\n  window = Window.partitionBy(col(\"ORIGIN_AIRPORT_ID\"))\\\n                     .orderBy(col(\"rounded_depTimestamp\"))\\\n                     .rowsBetween(0,3)\n  \n  cols_to_fill  = ['origin_HourlyAltimeterSetting', 'origin_HourlyDewPointTemperature', 'origin_HourlyDryBulbTemperature', 'origin_HourlyPrecipitation', 'origin_HourlyPressureChange', 'origin_HourlyPressureTendency', 'origin_HourlyRelativeHumidity', 'origin_HourlySeaLevelPressure', 'origin_HourlyStationPressure', 'origin_HourlyVisibility', 'origin_HourlyWetBulbTemperature', 'origin_HourlyWindDirection', 'origin_HourlyWindGustSpeed', 'origin_HourlyWindSpeed', 'origin_HourlySkyConditions_SCT_cnt', 'origin_HourlySkyConditions_OVC_cnt', 'origin_HourlySkyConditions_FEW_cnt', 'origin_HourlySkyConditions_BKN_cnt', 'origin_HourlySkyConditions_VV_cnt', 'origin_HourlySkyConditions_SKC_cnt', 'origin_HourlySkyConditions_CLR_cnt', 'dest_HourlyAltimeterSetting', 'dest_HourlyDewPointTemperature', 'dest_HourlyDryBulbTemperature', 'dest_HourlyPrecipitation', 'dest_HourlyPressureChange', 'dest_HourlyPressureTendency', 'dest_HourlyRelativeHumidity', 'dest_HourlySeaLevelPressure', 'dest_HourlyStationPressure', 'dest_HourlyVisibility', 'dest_HourlyWetBulbTemperature', 'dest_HourlyWindDirection','dest_HourlyWindGustSpeed', 'dest_HourlyWindSpeed', 'dest_HourlySkyConditions_SCT_cnt', 'dest_HourlySkyConditions_OVC_cnt', 'dest_HourlySkyConditions_FEW_cnt', 'dest_HourlySkyConditions_BKN_cnt', 'dest_HourlySkyConditions_VV_cnt', 'dest_HourlySkyConditions_SKC_cnt', 'dest_HourlySkyConditions_CLR_cnt']\n\n  \n  for field in cols_to_fill:\n      filled_column_start = first(df[field], ignorenulls=True).over(window)\n      df = df.withColumn(field, filled_column_start)\n  \n  ## We are still left with some null values --> will deal with them now in accordance to the table in section VII of this notebook\n  impute_minus1int = ['DEP_DELAY_NEW', 'holiday' ,'holiday_in2DayRange']\n  df = df.na.fill(value = -1,subset = impute_minus1int)\n  \n  impute_minus9999int = ['DEP_DELAY']\n  df = df.na.fill(value = -9999,subset = impute_minus9999int)\n  \n  impute_minus1fl = ['perc_delays_last1d', 'perc_cancellation_last1d']\n  df = df.na.fill(value = -1.0,subset = impute_minus1fl)\n  \n  impute_minus9999int = ['elevation_ft']\n  df = df.na.fill(value = -9999,subset = impute_minus9999int)\n  \n  impute_99int = [ 'origin_HourlyRelativeHumidity', 'dest_HourlyRelativeHumidity']\n  df = df.na.fill(value = 99 ,subset = impute_99int)\n  \n  impute_99fl = ['origin_HourlyPrecipitation', 'dest_HourlyPrecipitation']\n  df = df.na.fill(value = 99.0 ,subset = impute_99fl)\n  \n  impute_999int = ['origin_HourlyPressureTendency', 'dest_HourlyPressureTendency']\n  df = df.na.fill(value = 999 ,subset = impute_999int)\n  \n  impute_999fl = ['origin_HourlyPressureChange', 'dest_HourlyPressureChange']\n  df = df.na.fill(value = 999.0 ,subset = impute_999fl)\n  \n  impute_9999int = ['origin_HourlyDewPointTemperature', 'origin_HourlyDryBulbTemperature', 'origin_HourlyWetBulbTemperature', 'origin_HourlyWindGustSpeed', 'dest_HourlyDewPointTemperature', 'dest_HourlyDryBulbTemperature', 'dest_HourlyWetBulbTemperature', 'dest_HourlyWindGustSpeed']\n  df = df.na.fill(value = 9999 ,subset = impute_9999int)\n    \n  impute_99999int = ['origin_HourlyWindDirection', 'origin_HourlyWindSpeed', 'dest_HourlyWindDirection', 'dest_HourlyWindSpeed']\n  df = df.na.fill(value = 99999 ,subset = impute_99999int)\n  \n  impute_99999fl = ['origin_HourlyAltimeterSetting',  'dest_HourlyAltimeterSetting', 'origin_HourlySeaLevelPressure','dest_HourlySeaLevelPressure', 'origin_HourlyStationPressure', 'dest_HourlyStationPressure']\n  df = df.na.fill(value = 99999.0 ,subset = impute_99999fl)\n  \n  impute_999999fl = ['origin_HourlyVisibility', 'dest_HourlyVisibility']\n  df = df.na.fill(value = 999999.0 ,subset = impute_999999fl)\n  \n  impute_str = ['TAIL_NUM', 'type', 'origin_HourlySkyConditions', 'dest_HourlySkyConditions', 'local_timestamp', 'timezone']\n  df = df.na.fill(value = 'no_data',subset = impute_str)\n  \n  imputed_cols  = cols_to_fill + ['perc_delays_last1d', 'perc_cancellation_last1d', 'elevation_ft']\n  \n  return df,imputed_cols"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"84065e67-f2fa-46b9-b7a5-f85a25dd46ff","inputWidgets":{},"title":"Function: Pre-Modeling Data Edit"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Function to create pipeline\ndef create_pipeline(df, inputCols_cat, inputCols_cont):\n  \"\"\"Creates a feature engineering pipeline for modeling \n  Args:\n    inputCols_cat (list): list of categorical input cols\n    inputCols_cont (list): list of continuous input cols \n  \n  Returns: \n    pipeline (Pipeline): MLlib pipeline with stages  \n  \"\"\"\n  \n  # String Indexer\n  inputCols_categorical_indexed = [f'{i}_index' for i in inputCols_cat]\n  string_indexer = StringIndexer(inputCols = inputCols_cat, \n                                 outputCols = inputCols_categorical_indexed).setHandleInvalid('keep')\n\n  # One Hot Encoder  \n  inputCols_categorical_encoded = [f'{i}_encoded' for i in inputCols_categorical_indexed]\n  one_hot_encoder = OneHotEncoder(inputCols = inputCols_categorical_indexed, \n                                  outputCols = inputCols_categorical_encoded)\n\n  # Vector Assembler (Categorical)\n  assembler_cat = VectorAssembler(inputCols = inputCols_categorical_encoded, \n                              outputCol = 'features_cat').setHandleInvalid('keep')\n  \n  # Vector Assembler (Continuous)\n  assembler_cont = VectorAssembler(inputCols = inputCols_cont, \n                              outputCol = 'features_cont').setHandleInvalid('keep')\n\n  # Pipeline\n  return Pipeline().setStages([string_indexer, one_hot_encoder, assembler_cat, assembler_cont])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"e3c4381e-e48f-4aa4-8544-e26c7e360cbc","inputWidgets":{},"title":"Pipeline Function"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def impute_and_scale_features(df):\n  \n  # Impute data \n  imputed_df, imputed_cols = preModeling_dataEdit(df)\n\n  # Vector Assembler (Continuous) \n  assembler_cont = VectorAssembler(inputCols = ['features_cont'] + imputed_cols, \n                              outputCol = 'features_cont_all').setHandleInvalid('keep')\n\n  # Standard Scaler \n  scaler = StandardScaler(inputCol = 'features_cont_all',\n                          outputCol = 'features_scaled',\n                          withMean = True, withStd = True)\n  \n  # Vector Assembler (Continuous + Categorical) \n  assembler_all = VectorAssembler(inputCols = ['features_scaled', 'features_cat'], \n                              outputCol = 'features_all').setHandleInvalid('keep')\n\n  pipeline = Pipeline().setStages([assembler_cont, scaler, assembler_all])\n\n  # Create features_scaled for all dfs\n  pipeline_df = pipeline.fit(imputed_df).transform(imputed_df) \n  \n  return  pipeline_df"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"caf54515-fd19-4f89-8e2f-18a157b5d625","inputWidgets":{},"title":"Function: Impute and Scale Features"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def get_sampling(train_df, sampling):\n  \"\"\"Modifies the training data to under/over sample \n  Args:\n    train_df (df): training data\n    sampling (string): if none, no sampling is performed; if under, undersampling is performed; if over, oversampling is performed \n  Returns:\n    train_df_sampled (df): modified training data \n  \"\"\"\n  train_df = train_df.filter(col('label') != 2)\n  # No sampling \n  if sampling == 'none':\n    return train_df\n  \n  # Undersampling\n  elif sampling == 'under':\n    no_delay = train_df.filter(col('label') == 0)\n    delay = train_df.filter(col('label') == 1)\n    \n    class_ratio =  delay.count() / no_delay.count()\n    no_delay_sample = no_delay.sample(withReplacement=True, fraction=class_ratio)\n    train_df_sampled = delay.unionAll(no_delay_sample)\n    \n    return train_df_sampled\n    \n  # Oversampling\n  elif sampling == 'over':\n    no_delay = train_df.filter(col('label') == 0) #3000\n    delay = train_df.filter(col('label') == 1) #700\n    \n    class_ratio = no_delay.count() / delay.count() #0.2\n    delay_sample = delay.sample(withReplacement=True, fraction=class_ratio)\n    train_df_sampled = no_delay.unionAll(delay_sample)\n    \n    return train_df_sampled"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"35b3f46a-3158-4eef-9bd7-63ec66211bcb","inputWidgets":{},"title":"Function: Get Sample"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def get_model(model_type, params, feature_count=None):\n  \"\"\"Builds a model based on the given parameters\n  Args:\n    model_type (string): type of model to be built \n    params (dict): dictionary of parameters specific to the model_type\n  Returns:\n    model: MLlib model ready to be trained \n    ml_type (string): type of model (classification or regression)\n  \"\"\"\n  # Logistic Regression\n  if model_type == 'LogisticRegression':\n    ml_type = 'c'\n    model = LogisticRegression(featuresCol = 'features_all',\n                               labelCol = 'label',\n                               maxIter = params['maxIter'],\n                               regParam = params['regParam'],\n                               elasticNetParam = params['elasticNetParam'])\n\n  # Linear Regression\n  elif model_type == 'LinearRegression':\n    ml_type = 'r'\n    model = LinearRegression(featuresCol = 'features_all',\n                             labelCol = 'DEP_DELAY_NEW',\n                             maxIter = params['maxIter'],\n                             regParam = params['regParam'],\n                             elasticNetParam = params['elasticNetParam'])\n\n  # Decision Tree Classifier\n  elif model_type == 'DecisionTreeClassifier':\n    ml_type = 'c'\n    model = DecisionTreeClassifier(featuresCol = 'features_all',\n                                   labelCol = 'label',\n                                   maxDepth = params['maxDepth'],\n                                   impurity = params['impurity'],\n                                   maxBins = params['maxBins'],\n                                   minInfoGain = params['minInfoGain'])\n    \n  # Decision Tree Regressor\n  elif model_type == 'DecisionTreeRegressor':\n    ml_type = 'r'\n    model = DecisionTreeRegressor(featuresCol = 'features_all',\n                                  labelCol = 'DEP_DELAY_NEW',\n                                  maxDepth = params['maxDepth'],\n                                  minInfoGain = params['minInfoGain'])\n\n  # Random Forest Classifier\n  elif model_type == 'RandomForestClassifier':\n    ml_type = 'c'\n    model = RandomForestClassifier(featuresCol = 'features_all',\n                                   labelCol='label',\n                                   numTrees= params['numTrees'], \n                                   maxDepth=params['maxDepth'], \n                                   impurity = params['impurity'],\n                                   maxBins = params['maxBins'],\n                                   minInfoGain = params['minInfoGain'])\n  \n  # Random Forest Regressor\n  elif model_type == 'RandomForestRegressor':\n    ml_type = 'r'\n    model = RandomForestRegressor(featuresCol = 'features_all',\n                                   labelCol='DEP_DELAY_NEW',\n                                   numTrees= params['numTrees'], \n                                   maxDepth=params['maxDepth'],\n                                   minInfoGain = params['minInfoGain'])\n\n  # Gradient Boosted Tree Regressor \n  elif model_type == 'GBTRegressor':\n    ml_type = 'r'\n    model = GBTRegressor(featuresCol = 'features_all',\n                         labelCol='DEP_DELAY_NEW',\n                         maxIter= params['maxIter'], \n                         maxDepth=params['maxDepth'],\n                         stepSize = params['stepSize'],\n                         minInfoGain = params['minInfoGain'])\n\n  # MLP NN Classifier \n  elif model_type == 'MultilayerPerceptronClassifier':\n    ml_type = 'c'\n    model = MultilayerPerceptronClassifier(featuresCol = 'features_all',\n                         labelCol='label',\n                         layers = [feature_count, 5, 4, 2],\n                         maxIter= params['maxIter'], \n                         blockSize=params['blockSize'],\n                         stepSize = params['stepSize'])\n\n  \n  return model, ml_type"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"aca15774-175d-46f3-9a4c-8c2e2db23e87","inputWidgets":{},"title":"Get Model"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def get_param_permutations(params):\n  \"\"\"Given a dictionary of parameters to test in a grid search, returns all possible permutations\n  Args:\n    params (dict): dictionary of parameters inputted by user\n  Returns:\n    param_list (list): list of dictionaries to pass to the model\n  \"\"\"\n  param_list = []\n  vals = params.values()\n\n  # Loop through all permutations \n  for param_vals in list(itertools.product(*vals)):\n    # Create a dictionary to hold each permutation of parameters \n    param_dict = {}\n    # Loop over the different parameters \n    for i, key in enumerate(params.keys()):\n      param_dict[key] = param_vals[i]\n    # Add each dictionary to the parameter list \n    param_list.append(param_dict)\n  return param_list "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"eb07fad7-08fb-4f0c-b204-963e5c744d6d","inputWidgets":{},"title":"Function: Get Paramater Permutations"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def evaluate_model(predictions, ml_type):\n  \"\"\"Provides evaluation metrics for classification/regression models\n  Args:\n    predictions (df): dataframe of predicated and actual values \n    ml_type (string): type of model \n  Returns:\n    classification: accuracy, precision, recall, f1score\n    regression: r2, rmse, mse, mae\n  \"\"\"\n  if ml_type == 'c':\n    eval_accuracy = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction')\n    eval_precision = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='precisionByLabel')\n    eval_recall = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='recallByLabel')\n    eval_f1 = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='f1')\n\n    accuracy = eval_accuracy.evaluate(predictions)\n    precision = eval_precision.evaluate(predictions)\n    recall = eval_recall.evaluate(predictions)\n    f1score = eval_f1.evaluate(predictions)\n    \n    return accuracy, precision, recall, f1score\n    \n  elif ml_type == 'r':\n    eval_r2 = RegressionEvaluator(predictionCol='prediction', labelCol='DEP_DELAY_NEW', metricName='r2')\n    eval_rmse = RegressionEvaluator(predictionCol='prediction', labelCol='DEP_DELAY_NEW', metricName='rmse')\n    eval_mse = RegressionEvaluator(predictionCol='prediction', labelCol='DEP_DELAY_NEW', metricName='mse')\n    eval_mae = RegressionEvaluator(predictionCol='prediction', labelCol='DEP_DELAY_NEW', metricName='mae')\n    \n    r2 = eval_r2.evaluate(predictions)\n    rmse = eval_rmse.evaluate(predictions)\n    mse = eval_mse.evaluate(predictions)\n    mae = eval_mae.evaluate(predictions)\n    \n    return r2, rmse, mse, mae"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"41d2587c-a0d3-4d1a-9997-3d3cce8a682f","inputWidgets":{},"title":"Function: Evaluate Model"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Modeling Functions"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"054b552c-e3d9-4bc0-94aa-15cdb63e7553","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def train_model_no_CV(train_df, val_df, model_type, params, train_metrics=False):\n  \"\"\"Splits the df into time series cross validation splits, trains a model, and provides evaluation metrics. Should be used for experimentation to determine best model parameters.\n  Args:\n    train_df (df): training data that has been through grid_search_test_train_split\n    val_df (df): validation data that has been through grid_search_test_train_split\n    model_type (string): indicates the type of model that will be trained \n    params (dict): a dictionary of parameters as keys and list of parameter values as values \n        - LogisticRegression: { 'maxIter': [10,20,30], 'regParam': [0.2,0.3,0.4], 'elasticNetParam': [0,0.8,0.9] }\n        - LinearRegression: { 'maxIter': [10,20,30], 'regParam': [0.2,0.3,0.4], 'elasticNetParam': [0,0.8,0.9] }\n        - DecisionTreeClassifier: { 'numClasses': [3], 'maxDepth': [2], 'impurity': ['gini'], 'maxBins': [32] }\n        - DecisionTreeRegressor: { 'maxDepth': [1,2,3] }\n  \n  Returns: \n    results_df (df):  dataframe of parameters tested and the results from that iteration  \n  feature_pipeline_model = (Pipeline()\n     .setStages(...)  # Only feature extraction\n     .fit(train_df))\n\n    train_df_features = feature_pipeline_model.transform(train_df)\n    layers = [\n        train_df_features.schema[\"features\"].metadata[\"ml_attr\"][\"num_attrs\"],\n        20, 10, 2\n    ]\n  \"\"\"\n\n  # ---------- Train Model ---------- #\n  param_permutations = get_param_permutations(params)\n\n  results_df = pd.DataFrame()\n  for param in param_permutations:\n    if model_type == 'MultilayerPerceptronClassifier':\n      model, ml_type = get_model(model_type, param, train_df.schema[\"features_all\"].metadata[\"ml_attr\"][\"num_attrs\"])\n    else:\n      model, ml_type = get_model(model_type, param)\n    trained_model  = model.fit(train_df)\n    \n    if train_metrics == True:\n      training_predictions = trained_model.transform(train_df)\n    predictions          = trained_model.transform(val_df)\n\n    # ---------- Evaluate Model ---------- #\n    iter_params = pd.DataFrame(param, index=[0])\n    \n    # Classification \n    if ml_type == 'c':\n      if train_metrics == True:\n        train_accuracy, train_precision, train_recall, train_f1score = evaluate_model(training_predictions, ml_type)\n        train_iter_results = pd.DataFrame({'Train Accuracy': [train_accuracy], 'Train Precision': [train_precision], 'Train Recall': [train_recall], 'Train F1 Score': [train_f1score]})\n      val_accuracy, val_precision, val_recall, val_f1score = evaluate_model(predictions, ml_type)\n      val_iter_results = pd.DataFrame({'Val Accuracy': [val_accuracy], 'Val Precision': [val_precision], 'Val Recall': [val_recall], 'Val F1 Score': [val_f1score]})\n\n    # Regression\n    elif ml_type == 'r':\n      if train_metrics == True:\n        train_r2, train_rmse, train_mse, train_mae = evaluate_model(training_predictions, ml_type)\n        train_iter_results = pd.DataFrame({'Train R2': [train_r2], 'Train RMSE': [train_rmse], 'Train MSE': [train_mse], 'Train MAE': [train_mae]})\n      val_r2, val_rmse, val_mse, val_mae = evaluate_model(predictions, ml_type)\n      val_iter_results = pd.DataFrame({'Val R2': [val_r2], 'Val RMSE': [val_rmse], 'Val MSE': [val_mse], 'Val MAE': [val_mae]})\n      \n    if train_metrics == True:\n      iter_df = pd.concat([iter_params, train_iter_results, val_iter_results], axis=1)  \n    else:\n      iter_df = pd.concat([iter_params, val_iter_results], axis=1)\n    results_df = pd.concat([results_df,iter_df], axis=0)\n  \n  return results_df"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"0ae4fe2f-f7a0-4018-b168-4f6aeaee6bcc","inputWidgets":{},"title":"Train Model No CV"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def train_model_CV(df, model_type, params, k=5, sampling='none'):\n  \"\"\"Splits the df into time series cross validation splits, trains a model, and provides evaluation metrics. This function shuold be used to evaluate performance metrics for various models. It should not be used for experimentation. (https://stats.stackexchange.com/questions/52274/how-to-choose-a-predictive-model-after-k-fold-cross-validation)\n  Args:\n    df (dataframe): dataframe to model on; requirements:\n      - Has gone through create_pipeline function \n      - Has 'Year' column from 2015 - 2021\n      - Has 'features' column (not scaled)\n      - Has 'label' column\n    model_type (string): indicates the type of model that will be trained \n    params (dict): a dictionary of parameters as keys and parameter values as values \n        - LogisticRegression: { 'maxIter': 10, 'regParam': 0.3, 'elasticNetParam': 0 }\n        - LinearRegression: { 'maxIter': 10, 'regParam': 0.3, 'elasticNetParam': 0 }\n        - DecisionTreeClassifier: { 'numClasses': 3, 'maxDepth': 2, 'impurity': 'gini', 'maxBins': 32 }\n        - DecisionTreeRegressor: { 'maxDepth': 2 }\n    k (int): number of folds to split data into\n    sampling (string): if none, no sampling is performed; if under, undersampling is performed; if over, oversampling is performed\n  \n  Returns: \n    results_df (df):  dataframe validation results from each fold \n    saved_model (model): returns the model that had the best validation performance of each fold \n  \"\"\"\n  results_df = pd.DataFrame()\n\n  # ---------- Split Data ---------- #\n  df_ranked = df.withColumn(\"rank\", row_number().over(Window.partitionBy().orderBy(\"scheduled_departure_UTC\")))\n  df_ranked = df_ranked.filter(col('Year') <= 2020).cache()\n  fold_size = df_ranked.count() / k\n\n  # Saved variables across folds\n  results_df = pd.DataFrame()\n  saved_model = None\n  saved_train_df = None \n  lowest_mae = 1000000\n  highest_f1 = 0\n  \n  for i in range(k):\n   \n    # Split the original dataframe into folds \n    fold_df = df_ranked.where(f\"{i * fold_size} < rank\").where(f\" rank <= {(i+1) * fold_size}\").drop(\"rank\")\n    # Split the fold into train and validation sets \n    fold_df_ranked = fold_df.withColumn(\"rank\", percent_rank().over(Window.partitionBy().orderBy(\"scheduled_departure_UTC\")))\n    train = fold_df_ranked.where(\"rank <= 0.7\").drop(\"rank\")\n    train = get_sampling(train, sampling)\n    val   = fold_df_ranked.where(\"rank >  0.7\").drop(\"rank\")\n    \n    # ---------- Impute and Scale Features ---------- #\n    train_df_full = impute_and_scale_features(train)\n    val_df_full   = impute_and_scale_features(val)\n\n    # ---------- Train Model ---------- #\n    #model, ml_type = get_model(model_type, params)\n    if model_type == 'MultilayerPerceptronClassifier':\n      model, ml_type = get_model(model_type, params, train_df_full.schema[\"features_all\"].metadata[\"ml_attr\"][\"num_attrs\"])\n    else:\n      model, ml_type = get_model(model_type, params)\n    trained_model  = model.fit(train_df_full)\n    predictions    = trained_model.transform(val_df_full)\n    \n    # ---------- Evaluate Model ---------- #\n    # Classification\n    if ml_type == 'c':\n      accuracy, precision, recall, f1score = evaluate_model(predictions, ml_type)\n      iter_params = pd.DataFrame(params, index=[0])\n      iter_results = pd.DataFrame({'Accuracy': [accuracy], 'Precision': [precision], 'Recall': [recall], 'F1 Score': [f1score]})\n      iter_df = pd.concat([iter_params, iter_results], axis=1)  \n      results_df = pd.concat([results_df,iter_df], axis=0)\n      \n      if f1score > highest_f1:\n        highest_f1     = f1score\n        saved_model    = trained_model\n        saved_train_df = train_df_full\n  \n    # Regression\n    elif ml_type == 'r':\n      r2, rmse, mse, mae = evaluate_model(predictions, ml_type)\n      iter_params = pd.DataFrame(params, index=[0])\n      iter_results = pd.DataFrame({'R2': [r2], 'RMSE': [rmse], 'MSE': [mse], 'MAE': [mae]})\n      iter_df = pd.concat([iter_params, iter_results], axis=1)  \n      results_df = pd.concat([results_df,iter_df], axis=0)\n    \n      if mae < lowest_mae:\n        lowest_mae     = mae\n        saved_model    = trained_model\n        saved_train_df = train_df_full\n  \n  # Clear memory \n  df_ranked.unpersist()\n  \n  return results_df, saved_model, saved_train_df"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"954a7373-c2b3-42fa-809f-f5f75fcbed69","inputWidgets":{},"title":"Train Model CV"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def grid_search_test_train_split(pipeline_df, sample_size, sampling='none'):\n  \"\"\"Splits the dataframe in train and test splits for grid search \n  Args:\n    df (dataframe): dataframe to model on; requirements:\n      - Has gone through create_pipeline function \n      - Has 'Year' column from 2015 - 2021\n      - Has 'features' column (not scaled)\n      - Has 'label' column\n    sample_size (float): optional parameter to specify if you would like a subset of the data \n    sampling (string): if none, no sampling is performed; if under, undersampling is performed; if over, oversampling is performed \n  \n  Returns: \n    results_df (df):  dataframe of parameters tested and the results from that iteration   \n  \"\"\"\n  # ---------- Split Data ---------- #\n  train = pipeline_df.filter(col('Year') <= 2019)\n  train = get_sampling(train, sampling)\n  val   = pipeline_df.filter(col('Year') == 2020)\n#   test  = pipeline_df.filter(col('Year') == 2021)\n\n  # ---------- Get Subset of Train & Val Data ---------- #\n  if sample_size:\n    train = train.sample(sample_size)\n    val = val.sample(sample_size)\n#     test = test.sample(sample_size)\n\n  # ---------- Impute and Scale Features ---------- #\n  train_df_full = impute_and_scale_features(train)\n  val_df_full   = impute_and_scale_features(val)\n#   test_df_full  = impute_and_scale_features(test)\n  \n  return train_df_full, val_df_full"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"d652f933-1207-4606-88ff-bd99707d4b80","inputWidgets":{},"title":"Grid Search Test Train Split"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["inputCols_categorical = ['MONTH','DAY_OF_WEEK', 'holiday_in2DayRange', 'C19', 'OP_UNIQUE_CARRIER', 'type', 'DEP_TIME_BLK']\ninputCols_continuous = ['DISTANCE']\n\npipeline = create_pipeline(df_full, inputCols_categorical, inputCols_continuous)\npipeline_df = pipeline.fit(df_full).transform(df_full)\npipeline_df = pipeline_df.filter(col('label') != 2)\n\ntrain_10_none, val_10_none = grid_search_test_train_split(pipeline_df, 0.1, sampling='none')\ntrain_10_none = train_10_none.cache()\nval_10_none  = val_10_none.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"fdcf93f4-6508-4d5a-8280-d26e373e7b53","inputWidgets":{},"title":"Pipeline Set Up & Grid Search"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["lin_reg_r_params = { 'maxIter': 20, 'regParam': 0.2, 'elasticNetParam': 0.8 }\nlr_10, lr_type_10 = get_model('LinearRegression', lin_reg_r_params)\n\nlr_trained_model_10  = lr_10.fit(train_10_none)\nlr_predictions_10    = lr_trained_model_10.transform(val_10_none)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"fdcbd554-3181-498b-b791-29576d102fd1","inputWidgets":{},"title":"Linear Regression"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["lr_10_eval_r2 = RegressionEvaluator(predictionCol='prediction', labelCol='DEP_DELAY_NEW', metricName='r2')\nlr_10_eval_rmse = RegressionEvaluator(predictionCol='prediction', labelCol='DEP_DELAY_NEW', metricName='rmse')\nlr_10_eval_mse = RegressionEvaluator(predictionCol='prediction', labelCol='DEP_DELAY_NEW', metricName='mse')\nlr_10_eval_mae = RegressionEvaluator(predictionCol='prediction', labelCol='DEP_DELAY_NEW', metricName='mae')\n\nr2_lr_10 = lr_10_eval_r2.evaluate(lr_predictions_10)\nrmse_lr_10 = lr_10_eval_rmse.evaluate(lr_predictions_10)\nmse_lr_10 = lr_10_eval_mse.evaluate(lr_predictions_10)\nmae_lr_10 = lr_10_eval_mae.evaluate(lr_predictions_10)\n\nlr_r_10_results = pd.DataFrame({'r2': [r2_lr_10], 'rmse': [rmse_lr_10], 'mse': [mse_lr_10], 'mae': [mae_lr_10]})\nprint(lr_r_10_results)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"7a614aa7-d4b6-48b8-9d9b-79745310cef9","inputWidgets":{},"title":"Linear Regression Results"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"         r2       rmse          mse        mae\n0  0.014964  35.315483  1247.183358  14.768823\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["         r2       rmse          mse        mae\n0  0.014964  35.315483  1247.183358  14.768823\n"]}}],"execution_count":0},{"cell_type":"code","source":["mlp_r_params = { 'maxIter': 20, 'stepSize': 0.03, 'blockSize': 300, 'seed': 1234, 'solver': 'gd'}\nmodel_10, ml_type_10 = get_model('MultilayerPerceptronClassifier', mlp_r_params, train_10_none.schema[\"features_all\"].metadata[\"ml_attr\"][\"num_attrs\"])\ntrained_model_10  = model_10.fit(train_10_none)\npredictions_10    = trained_model_10.transform(val_10_none)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"32143873-702a-482a-aeab-5aefa62a04ef","inputWidgets":{},"title":"Multi-Layer Perceptron Classifier - 10% sample"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["eval_accuracy_10 = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction')\neval_precision_10 = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='precisionByLabel')\neval_recall_10 = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='recallByLabel')\neval_f1_10 = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='f1')\n\naccuracy_10 = eval_accuracy_10.evaluate(predictions_10)\nprecision_10 = eval_precision_10.evaluate(predictions_10)\nrecall_10 = eval_recall_10.evaluate(predictions_10)\nf1score_10 = eval_f1_10.evaluate(predictions_10)\n\nmlp_c_10_results = pd.DataFrame({'Accuracy': [accuracy_10], 'Precision': [precision_10], 'Recall': [recall_10], 'F1 Score': [f1score_10]})\nprint(mlp_c_10_results)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"6d9a0a0d-1a24-4b2c-b68e-59208ce536f9","inputWidgets":{},"title":"MLPC 10% Sample Results"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"   Accuracy  Precision    Recall  F1 Score\n0  0.881305   0.917491  0.988715  0.881305\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["   Accuracy  Precision    Recall  F1 Score\n0  0.881305   0.917491  0.988715  0.881305\n"]}}],"execution_count":0},{"cell_type":"code","source":["def prepare_for_regression(df):\n  df = df.drop(*['probability', 'rawPrediction'])\n  df = df.withColumnRenamed(\"prediction\",\"MLP_10_class_prediction\")\n  return df"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"13536053-abfa-45a5-a929-fdf1dc3d42d5","inputWidgets":{},"title":"Function: Prepare Predictions for Regression"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["new_train_10 = prepare_for_regression(predictions_10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9ddd10d8-a40a-4e24-a1fd-760c1c92b093","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["lin_reg_r_params = { 'maxIter': 20, 'regParam': 0.2, 'elasticNetParam': 0.8 }\nlr_10, lr_type_10 = get_model('LinearRegression', lin_reg_r_params)\n\nlr_trained_model_10  = lr_10.fit(new_train_10)\nlr_predictions_10    = lr_trained_model_10.transform(val_10_none)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"66de0338-adac-406b-96d6-49e1f8eb9193","inputWidgets":{},"title":"Linear Regression using MLP predictions"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["lr_10_eval_r2 = RegressionEvaluator(predictionCol='prediction', labelCol='DEP_DELAY_NEW', metricName='r2')\nlr_10_eval_rmse = RegressionEvaluator(predictionCol='prediction', labelCol='DEP_DELAY_NEW', metricName='rmse')\nlr_10_eval_mse = RegressionEvaluator(predictionCol='prediction', labelCol='DEP_DELAY_NEW', metricName='mse')\nlr_10_eval_mae = RegressionEvaluator(predictionCol='prediction', labelCol='DEP_DELAY_NEW', metricName='mae')\n\nr2_lr_10 = lr_10_eval_r2.evaluate(lr_predictions_10)\nrmse_lr_10 = lr_10_eval_rmse.evaluate(lr_predictions_10)\nmse_lr_10 = lr_10_eval_mse.evaluate(lr_predictions_10)\nmae_lr_10 = lr_10_eval_mae.evaluate(lr_predictions_10)\nlr_r_10_results = pd.DataFrame({'r2': [r2_lr_10], 'rmse': [rmse_lr_10], 'mse': [mse_lr_10], 'mae': [mae_lr_10]})\nprint(lr_r_10_results)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5ecc610b-9e97-42a1-81dd-aa3727c7f89d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"         r2       rmse          mse        mae\n0  0.052012  34.644997  1200.275817  10.366102\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["         r2       rmse          mse        mae\n0  0.052012  34.644997  1200.275817  10.366102\n"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"528fa119-e839-4bb4-862e-87b7d613eb0e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Phase4_Model_Experimentation_Classification_to_Regression","dashboards":[{"elements":[],"guid":"fa48393d-f4de-42d1-8072-55b5d53e314b","layoutOption":{"stack":true,"grid":true},"version":"DashboardViewV1","nuid":"f2cef45d-5f24-4d86-8dac-7211a9028b47","origId":1215577238255678,"title":"Untitled","width":1024,"globalVars":{}},{"elements":[],"guid":"23a923fb-ee27-46dd-af73-ac77bc5d9ea2","layoutOption":{"stack":true,"grid":true},"version":"DashboardViewV1","nuid":"7114a47d-4d33-41d9-8389-66308ef55cf1","origId":1215577238255679,"title":"Untitled","width":1024,"globalVars":{}}],"notebookMetadata":{"pythonIndentUnit":2,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":4423519682322132,"dataframes":["_sqldf"]}},"language":"python","widgets":{},"notebookOrigID":1215577238255625}},"nbformat":4,"nbformat_minor":0}
